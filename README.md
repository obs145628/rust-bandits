# Bandits

Implementation of several techniques to maximize rewards in the k-arms bandit problem.


## Setup

```
cargo build
cargo run
```



## Algorithms

Several algorithms are implemented :
- Epsilon-greedy (with epsilon = 1/t)
- Optimal Initial Value
- UCB1 (Upper confidence Bound)
- Bayesian approach
